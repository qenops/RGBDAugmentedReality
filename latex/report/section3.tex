\section{System Design}
Our setup consists of a Kinect camera rigidly aligned to an Oculus Rift HMD (Figure  \todo[inline]{Add picture of rft and kinect} ). The kinect acquires RGBD images which as used as input to the KinectFusion algorithm. Using the RGBD images, KinectFusion estimates the camera pose and uses this to integrate the current depthmap into the reconstruction. Virtual content is generated by animating a rigged model of a virtual character. The reconstruction is rendered from the viewpoint of the eyes. The virtual content is then composited onto this. If the virtual content is transformed using the same tracking as the reconstruction then it remains aligned to the environment.The combination of the reconstruction and virtual content is then rendered onto the HMD. Figure \todo[inline]{Add system overview figure} shows the System Overview. 
\missingfigure{System Overview}

\missingfigure{Picture of Rift}


\input{section31}


\input{section32}

\input{section33}

\input{section34}

\input{section35}