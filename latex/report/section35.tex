\subsection{Display on HMD}
To render on the HMD, we draw our content on the framebuffer provided by Oculus Rift SDK for each eye. In order to ensure that the content looks correct through the oculus, we provide the desired FOV and texture size expected by the Rift to the KinectFusion API. Some further calibration was performed to ensure that objects in the Oculus appeared the same size as the real world. In our setup, the Kinect is placed above the Rift and thus the perspective from which its looks at the environment is different than the eye. We transform the Kinect to the pose of the centre of the Rift. Eye Position translations are then applied to get the poses for the eyes. The environment is rendered from each of the poses and passed to the Rift. The additional virtual content is rendered on the same buffers. The rift applies lens distortion correction and displays it.