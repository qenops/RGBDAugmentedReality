%%% template.tex
%%%
%%% This LaTeX source document can be used as the basis for your technical
%%% paper or abstract. Regardless of the length of your document, the commands
%%% are all the same.
%%% 
%%% The "\documentclass" command is the first command in your file. If you want to 
%%% prepare a version of your article with line numbers - a "review" version - 
%%% include the "review" parameter:
%%%    \documentclass[review]{acmsiggraph}
%%%


\documentclass{acmsiggraph}

%%%packages to include
\usepackage{todonotes}
%%% Title of your article or abstract.

\title{Fused AR Experience}

\author{David~Dunn\thanks{e-mail:dunn@unc.edu}\\Abdul~Rafay~Khalid\thanks{e-mail:arkhalid@cs.unc.edu}} 
\pdfauthor{Abdul~Rafay~Khalid}

%%% Used by the ``review'' variation; the online ID will be printed on 
%%% every page of the content.

\TOGonlineid{45678}

% User-generated keywords.

\keywords{KinectFusion, RGBD, Augmented Reality}

% With the "\setcopyright" command the appropriate rights management text will be added
% to your document.

%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
%\setcopyright{rightsretained}

% The year of publication in the "\copyrightyear" command.

\copyrightyear{2016}

%%% Conference information, from the completed rights management form.
%%% The "\conferenceinfo" command has two parameters: 
%%%    - conference name
%%%    - conference date and location
%%% The "\isbn" field includes the year and month after the article ISBN.

\conferenceinfo{SIGGRAPH 2016 Posters}{July 24-28, 2016, Anaheim, CA} 
\isbn{978-1-4503-ABCD-E/16/07} 
\doi{http://doi.acm.org/10.1145/9999997.9999999}

\begin{document}

%%% This is the ``teaser'' command, which puts an figure, centered, below 
%%% the title and author information, and above the body of the content.

 \teaser{
   \includegraphics[height=1.5in]{images/sampleteaser}
   \caption{Spring Training 2009, Peoria, AZ.}
 }

\maketitle

\begin{abstract}
Traditionally Augmented Reality has taken three main forms each with its own drawbacks. Optical see-through gives us a good view of the real world but it is difficult to show virtual objects effectively as occlusion cannot be achieved. Spatial Augmented reality doesn't allow the user to view the virtual content at the correct depth. The closest to approach to ours is Video See through augmented reality however it suffers from mismatch between the location of eye and the camera center. In recent years there has been a lot of work on accurately reconstructing a 3D representation of the environment using RGBD sensors. We propose a system that combines such a realtime reconstruction method with a Head mounted display to create a wide field of view Augmnented Reality system. 

\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010371.10010382</concept_id>
<concept_desc>Computing methodologies~Image manipulation</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010371.10010382.10010236</concept_id>
<concept_desc>Computing methodologies~Computational photography</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Image manipulation}
\ccsdesc[300]{Computing methodologies~Computational photography}

%
% End generated code
%

% The next three commands are required, and insert the user-generated keywords, 
% The CCS concepts list, and the rights management text.
% Please make sure there is a blank line between each of these three commands.

\keywordlist

\conceptlist

\printcopyright

\section{Introduction}


Recent advances in reconstruction methods means that we can create a 3D representation of an environment in real time. The ability of these methods lead us to imagine an alternate form of Augmented Reality. By attaching an RGBD sensor to a VR HMD we can reconstruct the environment around the user as he moves around in his environment. As we have a 3D model of the environment we can render the view from each of the user's eyes. This enables us to accurately reproduce the real environment of the user in stereo. Virtual content can then be composited over the model of the real environment. By using the tracking from the reconstruction method we can align the virtual content with the reconstruction. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=3.0in]{images/ferrari_laferrari}
	\caption{Ferrari LaFerrari. Image courtesy Flickr user ``gfreeman23.''}
	\label{fig:ferrari}
\end{figure}
\section{Related Work}





\input{section3}

\section*{Acknowledgements}

To Robert, for all the bagels.

\bibliographystyle{acmsiggraph}
\nocite{*}
\bibliography{template}
\end{document}
